diff --git a/docs/examples/distributed/001_single_gpu/job.sh b/docs/examples/distributed/002_multi_gpu/job.sh
index 6dd819b..41eed45 100644
--- a/docs/examples/distributed/001_single_gpu/job.sh
+++ b/docs/examples/distributed/002_multi_gpu/job.sh
@@ -1,7 +1,7 @@
 #!/bin/bash
 #SBATCH --gpus-per-task=rtx8000:1
-#SBATCH --cpus-per-task=4
-#SBATCH --ntasks-per-node=1
+#SBATCH --cpus-per-task=1
+#SBATCH --ntasks-per-node=4
 #SBATCH --mem=16G
 #SBATCH --time=00:15:00

@@ -26,10 +26,12 @@ module load anaconda/3
 # Activate pre-existing environment.
 conda activate pytorch

-
 # Stage dataset into $SLURM_TMPDIR
 cp -a /network/datasets/cifar10.var/cifar10_torchvision $SLURM_TMPDIR

+# Get a unique port for this job based on the job ID
+export MASTER_PORT=$(expr 10000 + $(echo -n $SLURM_JOBID | tail -c 4))
+export MASTER_ADDR="127.0.0.1"

-# Execute Python script
-python main.py
+# Execute Python script in each task (one per GPU)
+srun python main.py
